{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Use CML API to Define a Job Which Populates Chroma Vector DB\n",
    "In exercise 2 you went through the manual steps to create a dependent job. This exercise will do the same using CML APIv2. The benefit to using the CML API to create a job is that the user can then take a programmatic approach to creating jobs and then running them. Using the cmlapi library to create jobs is beneficial because it enables automation, version control, reproducibility, integration, scalability, error handling, and efficiency in job management, streamlining data processing workflows. \n",
    "\n",
    "![Populate Chroma architecture](../assets/exercise_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Declare imports, create CML API client, and list available runtimes\n",
    "Imports necessary modules, define a collection name, initialize a CML client, and retrieve a list of available runtimes that match specific criteria, printing the list of available runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'next_page_token': '',\n",
      " 'runtimes': [{'description': 'Python runtime with CUDA libraries provided by '\n",
      "                              'Cloudera',\n",
      "               'edition': 'Nvidia GPU',\n",
      "               'editor': 'JupyterLab',\n",
      "               'full_version': '2023.08.1-b6',\n",
      "               'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.08.1-b6',\n",
      "               'kernel': 'Python 3.10',\n",
      "               'register_user_id': 0,\n",
      "               'status': 'ENABLED'},\n",
      "              {'description': 'Python runtime with CUDA libraries provided by '\n",
      "                              'Cloudera',\n",
      "               'edition': 'Nvidia GPU',\n",
      "               'editor': 'JupyterLab',\n",
      "               'full_version': '2023.12.1-b8',\n",
      "               'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.12.1-b8',\n",
      "               'kernel': 'Python 3.10',\n",
      "               'register_user_id': 0,\n",
      "               'status': 'ENABLED'}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "COLLECTION_NAME = 'cml-default' ## Update if you have changed this\n",
    "    \n",
    "client = cmlapi.default_client(url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"), cml_api_key=os.getenv(\"CDSW_APIV2_KEY\"))\n",
    "available_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "    \"kernel\": \"Python 3.10\",\n",
    "    \"edition\": \"Nvidia GPU\",\n",
    "    \"editor\": \"JupyterLab\"\n",
    "}))\n",
    "print(available_runtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Retrieve the latest ML Runtime Identifier and save to an environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Python runtime with CUDA libraries provided by Cloudera',\n",
      " 'edition': 'Nvidia GPU',\n",
      " 'editor': 'JupyterLab',\n",
      " 'full_version': '2023.12.1-b8',\n",
      " 'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.12.1-b8',\n",
      " 'kernel': 'Python 3.10',\n",
      " 'register_user_id': 0,\n",
      " 'status': 'ENABLED'}\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-cuda:2023.12.1-b8\n"
     ]
    }
   ],
   "source": [
    "## Set available runtimes to the latest runtime in the environment (iterator is the number that begins with 0 and advances sequentially)\n",
    "## The JOB_IMAGE_ML_RUNTIME variable stores the ML Runtime which will be used to launch the job\n",
    "print(available_runtimes.runtimes[1])\n",
    "print(available_runtimes.runtimes[1].image_identifier)\n",
    "JOB_IMAGE_ML_RUNTIME = available_runtimes.runtimes[1].image_identifier\n",
    "\n",
    "## Store the ML Runtime for any future jobs in an environment variable so we don't have to do this step again\n",
    "os.environ['JOB_IMAGE_ML_RUNTIME'] = JOB_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Get the current working project\n",
    "Get and print the metadata of the current working project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2024, 1, 22, 21, 59, 16, 396916, tzinfo=tzlocal()),\n",
      " 'creation_status': 'success',\n",
      " 'creator': {'email': 'aakulov@cloudera.com',\n",
      "             'name': 'Oleksandr Akulov',\n",
      "             'username': 'aakulov'},\n",
      " 'default_engine_type': 'ml_runtime',\n",
      " 'description': 'This AMP is used for Cloudera Machine Learning Hands on Labs '\n",
      "                \"and focuses on CML's integrations with external components as \"\n",
      "                'well as running\\n'\n",
      "                'use case entirely in CML.\\n',\n",
      " 'environment': '{\"AWS_ACCESS_KEY_ID\":\"AKIA6JC4SHPOIIQP67U4\",\"AWS_SECRET_ACCESS_KEY\":\"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\",\"AWS_DEFAULT_REGION\":\"us-west-2\",\"PINECONE_API_KEY\":\"1f4bbd94-e744-42aa-bc9e-18fd2f879a60\",\"PINECONE_ENVIRONMENT\":\"gcp-starter\",\"PINECONE_INDEX\":\"cml-hol-index\",\"CDSW_APP_POLLING_ENDPOINT\":\"/\",\"PROJECT_OWNER\":\"aakulov\"}',\n",
      " 'ephemeral_storage_limit': 20,\n",
      " 'ephemeral_storage_request': 0,\n",
      " 'id': 'oarq-z71z-qav9-6dqw',\n",
      " 'name': 'Hands on Lab Workshop with LLM - aakulov 1',\n",
      " 'owner': {'email': 'aakulov@cloudera.com',\n",
      "           'name': 'Oleksandr Akulov',\n",
      "           'username': 'aakulov'},\n",
      " 'permissions': {'admin': True,\n",
      "                 'business_user': True,\n",
      "                 'inherit': False,\n",
      "                 'operator': True,\n",
      "                 'read': True,\n",
      "                 'write': True},\n",
      " 'shared_memory_limit': 0,\n",
      " 'updated_at': datetime.datetime(2024, 1, 25, 19, 18, 26, 146379, tzinfo=tzlocal()),\n",
      " 'visibility': 'private'}\n"
     ]
    }
   ],
   "source": [
    "project = client.get_project(project_id=os.getenv(\"CDSW_PROJECT_ID\"))\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Create and Run Job to Populate Chroma Vector DB\n",
    "\n",
    "This code generates a random identifier, creates a job request for populating a Chroma Vector database with specified parameters such as project ID, script, and resource allocation, and then creates the job and a corresponding job run within the Cloudera Machine Learning environment, effectively initiating a task to populate the vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_id=''.join(random.choice(string.ascii_lowercase) for i in range(10))\n",
    "job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project.id,\n",
    "    name = \"Populate Chroma Vector DB \" + random_id, \n",
    "    script = \"5_populate_local_chroma_db/populate_chroma_vectors.py\",\n",
    "    cpu = 1,\n",
    "    memory = 4,\n",
    "    runtime_identifier = os.getenv('JOB_IMAGE_ML_RUNTIME')\n",
    ")\n",
    "\n",
    "job_result = client.create_job(\n",
    "    body = job_body, \n",
    "    project_id = str(project.id)\n",
    ")\n",
    "\n",
    "job_run = client.create_job_run(\n",
    "    cmlapi.CreateJobRunRequest(),\n",
    "    project_id = project.id, \n",
    "    job_id = job_result.id\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
